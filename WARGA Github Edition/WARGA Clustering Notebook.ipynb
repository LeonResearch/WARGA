{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch import optim\n",
    "from model import GCNModelAE, Regularizer\n",
    "from optimizer import loss_function1\n",
    "from utils import load_data, preprocess_graph, get_roc_score, load_data_with_labels\n",
    "from sklearn.cluster import KMeans\n",
    "from metrics import clustering_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper-parameter Settings\n",
    "\n",
    "Here in node clustering we only use half of the training iterations for link prediction (i.e. 100 epochs for Cora and Citeseer, and 750 epochs for PubMed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=0, help='Random seed.')\n",
    "parser.add_argument('--epochs', type=int, default=100, help='Number of epochs to train.')\n",
    "parser.add_argument('--hidden1', type=int, default=32, help='Number of units in the first encoding layer.')\n",
    "parser.add_argument('--hidden2', type=int, default=16, help='Number of units in the second embedding layer.')\n",
    "parser.add_argument('--hidden3', type=int, default=16, help='Number of units in the first hidden layer of Regularizer.')\n",
    "parser.add_argument('--hidden4', type=int, default=64, help='Number of units in the second hidden layer of Regularizer.')\n",
    "parser.add_argument('--clamp', type=float, default=0.01, help='Weight clamp for Regularizer Parameters.')\n",
    "parser.add_argument('--lr', type=float, default=0.001, help='Initial learning rate for Generator.')\n",
    "parser.add_argument('--reglr', type=float, default=0.001, help='Initial learning rate for Regularizer.')\n",
    "parser.add_argument('--dropout', type=float, default=0., help='Dropout rate (1 - keep probability).')\n",
    "parser.add_argument('--dataset-str', type=str, default='cora', help='type of dataset.')\n",
    "\n",
    "args,unknown = parser.parse_known_args()\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)    \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for Node Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gae_for(args):\n",
    "    print(\"Using {} dataset\".format(args.dataset_str))\n",
    "    adj, features,true_labels = load_data_with_labels(args.dataset_str)\n",
    "    n_nodes, feat_dim = features.shape\n",
    "    features = features.to(device)\n",
    "    \n",
    "    if args.dataset_str == 'cora':\n",
    "        n_clusters = 7\n",
    "    elif args.dataset_str == 'citeseer':\n",
    "        n_clusters = 6\n",
    "    else:\n",
    "        n_clusters = 3\n",
    "\n",
    "    # Store original adjacency matrix (without diagonal entries) for later\n",
    "    adj_orig = adj\n",
    "    adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
    "    adj_orig.eliminate_zeros()\n",
    "\n",
    "    # Some preprocessing\n",
    "    adj_norm = preprocess_graph(adj)\n",
    "    adj_norm = adj_norm.to(device)\n",
    "    \n",
    "    adj_label = adj + sp.eye(adj.shape[0])\n",
    "    adj_label = torch.FloatTensor(adj_label.toarray())\n",
    "    adj_label = adj_label.to(device)\n",
    "\n",
    "    pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
    "    norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
    "\n",
    "    model = GCNModelAE(feat_dim, args.hidden1, args.hidden2, args.dropout).to(device)\n",
    "    regularizer = Regularizer(args.hidden3, args.hidden2, args.hidden4).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    regularizer_optimizer = optim.Adam(regularizer.parameters(), lr=args.reglr)\n",
    "    \n",
    "    clustering_scores=[]\n",
    "    for epoch in range(args.epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        regularizer.train() \n",
    "        \n",
    "        #Generate embeddings\n",
    "        predicted_labels_prob, emb = model(features, adj_norm)\n",
    "        \n",
    "        #Wasserstein Regularizer\n",
    "        for i in range(1):\n",
    "            f_z = regularizer(emb).to(device)\n",
    "            r = torch.normal(0.0, 1.0, [n_nodes, args.hidden2]).to(device)\n",
    "            f_r = regularizer(r)          \n",
    "            reg_loss = - f_r.mean() + f_z.mean() \n",
    "            \n",
    "            regularizer_optimizer.zero_grad()\n",
    "            reg_loss.backward(retain_graph=True)\n",
    "            regularizer_optimizer.step()\n",
    "            \n",
    "            # weight clamp\n",
    "            for p in regularizer.parameters():\n",
    "                p.data.clamp_(-args.clamp, args.clamp)\n",
    "        \n",
    "        #GAE Update\n",
    "        f_z = regularizer(emb)  \n",
    "        generator_loss = -f_z.mean()\n",
    "        loss = loss_function1(preds=predicted_labels_prob, labels=adj_label,\n",
    "                             norm=norm, pos_weight=torch.tensor(pos_weight))\n",
    "        loss = loss + generator_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        cur_loss = loss.item()\n",
    "        optimizer.step()\n",
    "     \n",
    "        print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(cur_loss))\n",
    "        print(\"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "        \n",
    "    np_emb = emb.cpu().detach().numpy()\n",
    "    kmeans = KMeans(n_clusters= n_clusters, random_state=args.seed).fit(np_emb)\n",
    "    predict_labels = kmeans.predict(np_emb)\n",
    "    cm = clustering_metrics(true_labels, predict_labels)\n",
    "    acc, nmi, f1_macro, precision_macro, adjscore = cm.evaluationClusterModelFromLabel()\n",
    "\n",
    "    clustering_scores.append([acc, nmi, f1_macro, precision_macro, adjscore])\n",
    " \n",
    "    return clustering_scores[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 0\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.77257\n",
      "time= 0.71816\n",
      "Epoch: 0002 train_loss= 0.76917\n",
      "time= 0.02294\n",
      "Epoch: 0003 train_loss= 0.76390\n",
      "time= 0.03092\n",
      "Epoch: 0004 train_loss= 0.75801\n",
      "time= 0.02892\n",
      "Epoch: 0005 train_loss= 0.75339\n",
      "time= 0.02693\n",
      "Epoch: 0006 train_loss= 0.75271\n",
      "time= 0.03391\n",
      "Epoch: 0007 train_loss= 0.75705\n",
      "time= 0.03391\n",
      "Epoch: 0008 train_loss= 0.76170\n",
      "time= 0.02892\n",
      "Epoch: 0009 train_loss= 0.76304\n",
      "time= 0.02943\n",
      "Epoch: 0010 train_loss= 0.76217\n",
      "time= 0.03192\n",
      "Epoch: 0011 train_loss= 0.76105\n",
      "time= 0.02693\n",
      "Epoch: 0012 train_loss= 0.75910\n",
      "time= 0.02731\n",
      "Epoch: 0013 train_loss= 0.75681\n",
      "time= 0.01795\n",
      "Epoch: 0014 train_loss= 0.75384\n",
      "time= 0.02194\n",
      "Epoch: 0015 train_loss= 0.75081\n",
      "time= 0.02693\n",
      "Epoch: 0016 train_loss= 0.74726\n",
      "time= 0.02944\n",
      "Epoch: 0017 train_loss= 0.74304\n",
      "time= 0.02693\n",
      "Epoch: 0018 train_loss= 0.73815\n",
      "time= 0.03491\n",
      "Epoch: 0019 train_loss= 0.73270\n",
      "time= 0.02793\n",
      "Epoch: 0020 train_loss= 0.72682\n",
      "time= 0.02793\n",
      "Epoch: 0021 train_loss= 0.72065\n",
      "time= 0.02394\n",
      "Epoch: 0022 train_loss= 0.71425\n",
      "time= 0.02694\n",
      "Epoch: 0023 train_loss= 0.70764\n",
      "time= 0.02891\n",
      "Epoch: 0024 train_loss= 0.70079\n",
      "time= 0.01795\n",
      "Epoch: 0025 train_loss= 0.69368\n",
      "time= 0.01695\n",
      "Epoch: 0026 train_loss= 0.68630\n",
      "time= 0.01695\n",
      "Epoch: 0027 train_loss= 0.67872\n",
      "time= 0.02992\n",
      "Epoch: 0028 train_loss= 0.67098\n",
      "time= 0.02793\n",
      "Epoch: 0029 train_loss= 0.66314\n",
      "time= 0.02693\n",
      "Epoch: 0030 train_loss= 0.65526\n",
      "time= 0.02892\n",
      "Epoch: 0031 train_loss= 0.64743\n",
      "time= 0.03889\n",
      "Epoch: 0032 train_loss= 0.63969\n",
      "time= 0.02294\n",
      "Epoch: 0033 train_loss= 0.63212\n",
      "time= 0.02693\n",
      "Epoch: 0034 train_loss= 0.62477\n",
      "time= 0.02493\n",
      "Epoch: 0035 train_loss= 0.61770\n",
      "time= 0.02793\n",
      "Epoch: 0036 train_loss= 0.61095\n",
      "time= 0.02493\n",
      "Epoch: 0037 train_loss= 0.60455\n",
      "time= 0.01795\n",
      "Epoch: 0038 train_loss= 0.59850\n",
      "time= 0.01795\n",
      "Epoch: 0039 train_loss= 0.59280\n",
      "time= 0.03192\n",
      "Epoch: 0040 train_loss= 0.58746\n",
      "time= 0.03391\n",
      "Epoch: 0041 train_loss= 0.58250\n",
      "time= 0.03291\n",
      "Epoch: 0042 train_loss= 0.57790\n",
      "time= 0.02992\n",
      "Epoch: 0043 train_loss= 0.57365\n",
      "time= 0.02992\n",
      "Epoch: 0044 train_loss= 0.56972\n",
      "time= 0.03192\n",
      "Epoch: 0045 train_loss= 0.56606\n",
      "time= 0.02892\n",
      "Epoch: 0046 train_loss= 0.56266\n",
      "time= 0.03192\n",
      "Epoch: 0047 train_loss= 0.55950\n",
      "time= 0.02892\n",
      "Epoch: 0048 train_loss= 0.55656\n",
      "time= 0.02992\n",
      "Epoch: 0049 train_loss= 0.55384\n",
      "time= 0.02294\n",
      "Epoch: 0050 train_loss= 0.55131\n",
      "time= 0.02194\n",
      "Epoch: 0051 train_loss= 0.54895\n",
      "time= 0.02094\n",
      "Epoch: 0052 train_loss= 0.54673\n",
      "time= 0.02992\n",
      "Epoch: 0053 train_loss= 0.54464\n",
      "time= 0.02892\n",
      "Epoch: 0054 train_loss= 0.54265\n",
      "time= 0.02793\n",
      "Epoch: 0055 train_loss= 0.54076\n",
      "time= 0.02793\n",
      "Epoch: 0056 train_loss= 0.53896\n",
      "time= 0.02793\n",
      "Epoch: 0057 train_loss= 0.53724\n",
      "time= 0.02593\n",
      "Epoch: 0058 train_loss= 0.53559\n",
      "time= 0.03193\n",
      "Epoch: 0059 train_loss= 0.53399\n",
      "time= 0.03391\n",
      "Epoch: 0060 train_loss= 0.53247\n",
      "time= 0.02492\n",
      "Epoch: 0061 train_loss= 0.53101\n",
      "time= 0.01696\n",
      "Epoch: 0062 train_loss= 0.52961\n",
      "time= 0.01795\n",
      "Epoch: 0063 train_loss= 0.52828\n",
      "time= 0.01695\n",
      "Epoch: 0064 train_loss= 0.52700\n",
      "time= 0.01696\n",
      "Epoch: 0065 train_loss= 0.52578\n",
      "time= 0.01795\n",
      "Epoch: 0066 train_loss= 0.52461\n",
      "time= 0.01995\n",
      "Epoch: 0067 train_loss= 0.52347\n",
      "time= 0.01895\n",
      "Epoch: 0068 train_loss= 0.52238\n",
      "time= 0.01895\n",
      "Epoch: 0069 train_loss= 0.52133\n",
      "time= 0.01894\n",
      "Epoch: 0070 train_loss= 0.52030\n",
      "time= 0.01695\n",
      "Epoch: 0071 train_loss= 0.51931\n",
      "time= 0.01596\n",
      "Epoch: 0072 train_loss= 0.51834\n",
      "time= 0.02194\n",
      "Epoch: 0073 train_loss= 0.51739\n",
      "time= 0.02195\n",
      "Epoch: 0074 train_loss= 0.51647\n",
      "time= 0.01994\n",
      "Epoch: 0075 train_loss= 0.51557\n",
      "time= 0.01696\n",
      "Epoch: 0076 train_loss= 0.51470\n",
      "time= 0.01995\n",
      "Epoch: 0077 train_loss= 0.51385\n",
      "time= 0.02094\n",
      "Epoch: 0078 train_loss= 0.51303\n",
      "time= 0.01895\n",
      "Epoch: 0079 train_loss= 0.51223\n",
      "time= 0.01995\n",
      "Epoch: 0080 train_loss= 0.51146\n",
      "time= 0.01695\n",
      "Epoch: 0081 train_loss= 0.51072\n",
      "time= 0.01895\n",
      "Epoch: 0082 train_loss= 0.51000\n",
      "time= 0.01995\n",
      "Epoch: 0083 train_loss= 0.50930\n",
      "time= 0.01795\n",
      "Epoch: 0084 train_loss= 0.50862\n",
      "time= 0.01895\n",
      "Epoch: 0085 train_loss= 0.50795\n",
      "time= 0.01596\n",
      "Epoch: 0086 train_loss= 0.50730\n",
      "time= 0.01496\n",
      "Epoch: 0087 train_loss= 0.50666\n",
      "time= 0.01795\n",
      "Epoch: 0088 train_loss= 0.50602\n",
      "time= 0.01695\n",
      "Epoch: 0089 train_loss= 0.50540\n",
      "time= 0.01696\n",
      "Epoch: 0090 train_loss= 0.50478\n",
      "time= 0.01496\n",
      "Epoch: 0091 train_loss= 0.50418\n",
      "time= 0.01596\n",
      "Epoch: 0092 train_loss= 0.50357\n",
      "time= 0.01596\n",
      "Epoch: 0093 train_loss= 0.50298\n",
      "time= 0.01795\n",
      "Epoch: 0094 train_loss= 0.50239\n",
      "time= 0.01696\n",
      "Epoch: 0095 train_loss= 0.50181\n",
      "time= 0.01795\n",
      "Epoch: 0096 train_loss= 0.50124\n",
      "time= 0.01995\n",
      "Epoch: 0097 train_loss= 0.50068\n",
      "time= 0.02194\n",
      "Epoch: 0098 train_loss= 0.50014\n",
      "time= 0.02194\n",
      "Epoch: 0099 train_loss= 0.49960\n",
      "time= 0.02095\n",
      "Epoch: 0100 train_loss= 0.49908\n",
      "time= 0.01795\n",
      "ACC=0.653250, f1_macro=0.629955, precision_macro=0.645058, recall_macro=0.652351, f1_micro=0.653250, precision_micro=0.653250, recall_micro=0.653250, NMI=0.498641, ADJ_RAND_SCORE=0.429786\n",
      "Seed 1\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76904\n",
      "time= 0.02280\n",
      "Epoch: 0002 train_loss= 0.76282\n",
      "time= 0.02016\n",
      "Epoch: 0003 train_loss= 0.75505\n",
      "time= 0.02269\n",
      "Epoch: 0004 train_loss= 0.74715\n",
      "time= 0.01713\n",
      "Epoch: 0005 train_loss= 0.74088\n",
      "time= 0.02147\n",
      "Epoch: 0006 train_loss= 0.73879\n",
      "time= 0.01596\n",
      "Epoch: 0007 train_loss= 0.74084\n",
      "time= 0.02294\n",
      "Epoch: 0008 train_loss= 0.74242\n",
      "time= 0.02593\n",
      "Epoch: 0009 train_loss= 0.74083\n",
      "time= 0.02593\n",
      "Epoch: 0010 train_loss= 0.73709\n",
      "time= 0.01567\n",
      "Epoch: 0011 train_loss= 0.73267\n",
      "time= 0.01895\n",
      "Epoch: 0012 train_loss= 0.72836\n",
      "time= 0.02598\n",
      "Epoch: 0013 train_loss= 0.72397\n",
      "time= 0.02797\n",
      "Epoch: 0014 train_loss= 0.71953\n",
      "time= 0.02505\n",
      "Epoch: 0015 train_loss= 0.71517\n",
      "time= 0.02695\n",
      "Epoch: 0016 train_loss= 0.71036\n",
      "time= 0.02994\n",
      "Epoch: 0017 train_loss= 0.70521\n",
      "time= 0.02693\n",
      "Epoch: 0018 train_loss= 0.69932\n",
      "time= 0.02693\n",
      "Epoch: 0019 train_loss= 0.69282\n",
      "time= 0.02793\n",
      "Epoch: 0020 train_loss= 0.68587\n",
      "time= 0.02693\n",
      "Epoch: 0021 train_loss= 0.67864\n",
      "time= 0.02593\n",
      "Epoch: 0022 train_loss= 0.67125\n",
      "time= 0.01695\n",
      "Epoch: 0023 train_loss= 0.66374\n",
      "time= 0.01895\n",
      "Epoch: 0024 train_loss= 0.65609\n",
      "time= 0.02693\n",
      "Epoch: 0025 train_loss= 0.64826\n",
      "time= 0.02693\n",
      "Epoch: 0026 train_loss= 0.64024\n",
      "time= 0.02693\n",
      "Epoch: 0027 train_loss= 0.63213\n",
      "time= 0.02593\n",
      "Epoch: 0028 train_loss= 0.62402\n",
      "time= 0.02693\n",
      "Epoch: 0029 train_loss= 0.61602\n",
      "time= 0.02693\n",
      "Epoch: 0030 train_loss= 0.60819\n",
      "time= 0.02892\n",
      "Epoch: 0031 train_loss= 0.60056\n",
      "time= 0.02593\n",
      "Epoch: 0032 train_loss= 0.59315\n",
      "time= 0.02593\n",
      "Epoch: 0033 train_loss= 0.58598\n",
      "time= 0.02693\n",
      "Epoch: 0034 train_loss= 0.57909\n",
      "time= 0.01696\n",
      "Epoch: 0035 train_loss= 0.57252\n",
      "time= 0.01696\n",
      "Epoch: 0036 train_loss= 0.56623\n",
      "time= 0.02693\n",
      "Epoch: 0037 train_loss= 0.56020\n",
      "time= 0.02593\n",
      "Epoch: 0038 train_loss= 0.55441\n",
      "time= 0.02793\n",
      "Epoch: 0039 train_loss= 0.54887\n",
      "time= 0.02892\n",
      "Epoch: 0040 train_loss= 0.54361\n",
      "time= 0.02693\n",
      "Epoch: 0041 train_loss= 0.53863\n",
      "time= 0.02593\n",
      "Epoch: 0042 train_loss= 0.53392\n",
      "time= 0.03642\n",
      "Epoch: 0043 train_loss= 0.52947\n",
      "time= 0.02693\n",
      "Epoch: 0044 train_loss= 0.52527\n",
      "time= 0.02992\n",
      "Epoch: 0045 train_loss= 0.52136\n",
      "time= 0.01895\n",
      "Epoch: 0046 train_loss= 0.51778\n",
      "time= 0.01795\n",
      "Epoch: 0047 train_loss= 0.51454\n",
      "time= 0.02094\n",
      "Epoch: 0048 train_loss= 0.51165\n",
      "time= 0.02593\n",
      "Epoch: 0049 train_loss= 0.50912\n",
      "time= 0.02693\n",
      "Epoch: 0050 train_loss= 0.50692\n",
      "time= 0.02892\n",
      "Epoch: 0051 train_loss= 0.50504\n",
      "time= 0.02892\n",
      "Epoch: 0052 train_loss= 0.50343\n",
      "time= 0.03690\n",
      "Epoch: 0053 train_loss= 0.50205\n",
      "time= 0.02693\n",
      "Epoch: 0054 train_loss= 0.50085\n",
      "time= 0.02793\n",
      "Epoch: 0055 train_loss= 0.49977\n",
      "time= 0.02793\n",
      "Epoch: 0056 train_loss= 0.49875\n",
      "time= 0.02394\n",
      "Epoch: 0057 train_loss= 0.49774\n",
      "time= 0.01795\n",
      "Epoch: 0058 train_loss= 0.49671\n",
      "time= 0.01995\n",
      "Epoch: 0059 train_loss= 0.49563\n",
      "time= 0.01596\n",
      "Epoch: 0060 train_loss= 0.49451\n",
      "time= 0.02792\n",
      "Epoch: 0061 train_loss= 0.49334\n",
      "time= 0.02693\n",
      "Epoch: 0062 train_loss= 0.49213\n",
      "time= 0.02792\n",
      "Epoch: 0063 train_loss= 0.49090\n",
      "time= 0.02493\n",
      "Epoch: 0064 train_loss= 0.48966\n",
      "time= 0.02992\n",
      "Epoch: 0065 train_loss= 0.48842\n",
      "time= 0.02992\n",
      "Epoch: 0066 train_loss= 0.48721\n",
      "time= 0.02693\n",
      "Epoch: 0067 train_loss= 0.48604\n",
      "time= 0.02394\n",
      "Epoch: 0068 train_loss= 0.48491\n",
      "time= 0.02593\n",
      "Epoch: 0069 train_loss= 0.48384\n",
      "time= 0.02693\n",
      "Epoch: 0070 train_loss= 0.48283\n",
      "time= 0.02094\n",
      "Epoch: 0071 train_loss= 0.48188\n",
      "time= 0.01795\n",
      "Epoch: 0072 train_loss= 0.48099\n",
      "time= 0.02793\n",
      "Epoch: 0073 train_loss= 0.48014\n",
      "time= 0.02892\n",
      "Epoch: 0074 train_loss= 0.47935\n",
      "time= 0.02793\n",
      "Epoch: 0075 train_loss= 0.47860\n",
      "time= 0.02892\n",
      "Epoch: 0076 train_loss= 0.47788\n",
      "time= 0.02943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0077 train_loss= 0.47721\n",
      "time= 0.02593\n",
      "Epoch: 0078 train_loss= 0.47657\n",
      "time= 0.03590\n",
      "Epoch: 0079 train_loss= 0.47596\n",
      "time= 0.02593\n",
      "Epoch: 0080 train_loss= 0.47538\n",
      "time= 0.02992\n",
      "Epoch: 0081 train_loss= 0.47483\n",
      "time= 0.01994\n",
      "Epoch: 0082 train_loss= 0.47431\n",
      "time= 0.02094\n",
      "Epoch: 0083 train_loss= 0.47381\n",
      "time= 0.03092\n",
      "Epoch: 0084 train_loss= 0.47332\n",
      "time= 0.02792\n",
      "Epoch: 0085 train_loss= 0.47285\n",
      "time= 0.02793\n",
      "Epoch: 0086 train_loss= 0.47240\n",
      "time= 0.02992\n",
      "Epoch: 0087 train_loss= 0.47196\n",
      "time= 0.02593\n",
      "Epoch: 0088 train_loss= 0.47152\n",
      "time= 0.03391\n",
      "Epoch: 0089 train_loss= 0.47110\n",
      "time= 0.02793\n",
      "Epoch: 0090 train_loss= 0.47069\n",
      "time= 0.02593\n",
      "Epoch: 0091 train_loss= 0.47027\n",
      "time= 0.02934\n",
      "Epoch: 0092 train_loss= 0.46987\n",
      "time= 0.02094\n",
      "Epoch: 0093 train_loss= 0.46946\n",
      "time= 0.01895\n",
      "Epoch: 0094 train_loss= 0.46906\n",
      "time= 0.02992\n",
      "Epoch: 0095 train_loss= 0.46867\n",
      "time= 0.02693\n",
      "Epoch: 0096 train_loss= 0.46828\n",
      "time= 0.02892\n",
      "Epoch: 0097 train_loss= 0.46789\n",
      "time= 0.02693\n",
      "Epoch: 0098 train_loss= 0.46750\n",
      "time= 0.02693\n",
      "Epoch: 0099 train_loss= 0.46712\n",
      "time= 0.02892\n",
      "Epoch: 0100 train_loss= 0.46674\n",
      "time= 0.02693\n",
      "ACC=0.608936, f1_macro=0.567735, precision_macro=0.579074, recall_macro=0.588276, f1_micro=0.608936, precision_micro=0.608936, recall_micro=0.608936, NMI=0.493074, ADJ_RAND_SCORE=0.416182\n",
      "Seed 2\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.77400\n",
      "time= 0.02892\n",
      "Epoch: 0002 train_loss= 0.77008\n",
      "time= 0.03191\n",
      "Epoch: 0003 train_loss= 0.76464\n",
      "time= 0.03391\n",
      "Epoch: 0004 train_loss= 0.75723\n",
      "time= 0.02793\n",
      "Epoch: 0005 train_loss= 0.74873\n",
      "time= 0.02693\n",
      "Epoch: 0006 train_loss= 0.74029\n",
      "time= 0.02793\n",
      "Epoch: 0007 train_loss= 0.73394\n",
      "time= 0.02493\n",
      "Epoch: 0008 train_loss= 0.73197\n",
      "time= 0.01995\n",
      "Epoch: 0009 train_loss= 0.73343\n",
      "time= 0.01496\n",
      "Epoch: 0010 train_loss= 0.73326\n",
      "time= 0.02693\n",
      "Epoch: 0011 train_loss= 0.72965\n",
      "time= 0.02892\n",
      "Epoch: 0012 train_loss= 0.72450\n",
      "time= 0.02693\n",
      "Epoch: 0013 train_loss= 0.71817\n",
      "time= 0.02892\n",
      "Epoch: 0014 train_loss= 0.71250\n",
      "time= 0.03291\n",
      "Epoch: 0015 train_loss= 0.70817\n",
      "time= 0.03192\n",
      "Epoch: 0016 train_loss= 0.70458\n",
      "time= 0.02792\n",
      "Epoch: 0017 train_loss= 0.70115\n",
      "time= 0.02793\n",
      "Epoch: 0018 train_loss= 0.69722\n",
      "time= 0.02593\n",
      "Epoch: 0019 train_loss= 0.69260\n",
      "time= 0.02194\n",
      "Epoch: 0020 train_loss= 0.68723\n",
      "time= 0.01695\n",
      "Epoch: 0021 train_loss= 0.68116\n",
      "time= 0.02892\n",
      "Epoch: 0022 train_loss= 0.67455\n",
      "time= 0.02792\n",
      "Epoch: 0023 train_loss= 0.66755\n",
      "time= 0.02892\n",
      "Epoch: 0024 train_loss= 0.66032\n",
      "time= 0.02792\n",
      "Epoch: 0025 train_loss= 0.65293\n",
      "time= 0.02793\n",
      "Epoch: 0026 train_loss= 0.64541\n",
      "time= 0.02693\n",
      "Epoch: 0027 train_loss= 0.63770\n",
      "time= 0.02693\n",
      "Epoch: 0028 train_loss= 0.62977\n",
      "time= 0.02493\n",
      "Epoch: 0029 train_loss= 0.62159\n",
      "time= 0.02593\n",
      "Epoch: 0030 train_loss= 0.61321\n",
      "time= 0.03002\n",
      "Epoch: 0031 train_loss= 0.60473\n",
      "time= 0.01795\n",
      "Epoch: 0032 train_loss= 0.59628\n",
      "time= 0.01795\n",
      "Epoch: 0033 train_loss= 0.58796\n",
      "time= 0.02094\n",
      "Epoch: 0034 train_loss= 0.57986\n",
      "time= 0.02593\n",
      "Epoch: 0035 train_loss= 0.57208\n",
      "time= 0.02892\n",
      "Epoch: 0036 train_loss= 0.56467\n",
      "time= 0.02693\n",
      "Epoch: 0037 train_loss= 0.55770\n",
      "time= 0.02493\n",
      "Epoch: 0038 train_loss= 0.55121\n",
      "time= 0.03590\n",
      "Epoch: 0039 train_loss= 0.54519\n",
      "time= 0.02693\n",
      "Epoch: 0040 train_loss= 0.53963\n",
      "time= 0.02693\n",
      "Epoch: 0041 train_loss= 0.53449\n",
      "time= 0.02593\n",
      "Epoch: 0042 train_loss= 0.52972\n",
      "time= 0.03191\n",
      "Epoch: 0043 train_loss= 0.52529\n",
      "time= 0.01793\n",
      "Epoch: 0044 train_loss= 0.52116\n",
      "time= 0.01895\n",
      "Epoch: 0045 train_loss= 0.51728\n",
      "time= 0.01796\n",
      "Epoch: 0046 train_loss= 0.51360\n",
      "time= 0.02792\n",
      "Epoch: 0047 train_loss= 0.51009\n",
      "time= 0.03690\n",
      "Epoch: 0048 train_loss= 0.50672\n",
      "time= 0.02593\n",
      "Epoch: 0049 train_loss= 0.50347\n",
      "time= 0.01696\n",
      "Epoch: 0050 train_loss= 0.50034\n",
      "time= 0.03690\n",
      "Epoch: 0051 train_loss= 0.49735\n",
      "time= 0.02693\n",
      "Epoch: 0052 train_loss= 0.49450\n",
      "time= 0.02693\n",
      "Epoch: 0053 train_loss= 0.49181\n",
      "time= 0.02544\n",
      "Epoch: 0054 train_loss= 0.48930\n",
      "time= 0.02593\n",
      "Epoch: 0055 train_loss= 0.48698\n",
      "time= 0.01994\n",
      "Epoch: 0056 train_loss= 0.48486\n",
      "time= 0.01995\n",
      "Epoch: 0057 train_loss= 0.48293\n",
      "time= 0.01795\n",
      "Epoch: 0058 train_loss= 0.48116\n",
      "time= 0.03043\n",
      "Epoch: 0059 train_loss= 0.47953\n",
      "time= 0.02792\n",
      "Epoch: 0060 train_loss= 0.47800\n",
      "time= 0.02992\n",
      "Epoch: 0061 train_loss= 0.47655\n",
      "time= 0.02892\n",
      "Epoch: 0062 train_loss= 0.47516\n",
      "time= 0.02792\n",
      "Epoch: 0063 train_loss= 0.47379\n",
      "time= 0.02593\n",
      "Epoch: 0064 train_loss= 0.47245\n",
      "time= 0.02793\n",
      "Epoch: 0065 train_loss= 0.47113\n",
      "time= 0.02892\n",
      "Epoch: 0066 train_loss= 0.46982\n",
      "time= 0.02992\n",
      "Epoch: 0067 train_loss= 0.46853\n",
      "time= 0.02394\n",
      "Epoch: 0068 train_loss= 0.46727\n",
      "time= 0.01596\n",
      "Epoch: 0069 train_loss= 0.46603\n",
      "time= 0.01995\n",
      "Epoch: 0070 train_loss= 0.46482\n",
      "time= 0.01795\n",
      "Epoch: 0071 train_loss= 0.46365\n",
      "time= 0.03890\n",
      "Epoch: 0072 train_loss= 0.46252\n",
      "time= 0.03092\n",
      "Epoch: 0073 train_loss= 0.46142\n",
      "time= 0.02693\n",
      "Epoch: 0074 train_loss= 0.46037\n",
      "time= 0.02792\n",
      "Epoch: 0075 train_loss= 0.45936\n",
      "time= 0.02493\n",
      "Epoch: 0076 train_loss= 0.45839\n",
      "time= 0.02593\n",
      "Epoch: 0077 train_loss= 0.45745\n",
      "time= 0.02892\n",
      "Epoch: 0078 train_loss= 0.45656\n",
      "time= 0.02793\n",
      "Epoch: 0079 train_loss= 0.45571\n",
      "time= 0.02892\n",
      "Epoch: 0080 train_loss= 0.45490\n",
      "time= 0.01496\n",
      "Epoch: 0081 train_loss= 0.45413\n",
      "time= 0.01995\n",
      "Epoch: 0082 train_loss= 0.45341\n",
      "time= 0.02992\n",
      "Epoch: 0083 train_loss= 0.45272\n",
      "time= 0.02793\n",
      "Epoch: 0084 train_loss= 0.45206\n",
      "time= 0.03191\n",
      "Epoch: 0085 train_loss= 0.45143\n",
      "time= 0.02992\n",
      "Epoch: 0086 train_loss= 0.45083\n",
      "time= 0.02693\n",
      "Epoch: 0087 train_loss= 0.45025\n",
      "time= 0.02693\n",
      "Epoch: 0088 train_loss= 0.44969\n",
      "time= 0.02892\n",
      "Epoch: 0089 train_loss= 0.44914\n",
      "time= 0.02693\n",
      "Epoch: 0090 train_loss= 0.44862\n",
      "time= 0.02892\n",
      "Epoch: 0091 train_loss= 0.44811\n",
      "time= 0.01895\n",
      "Epoch: 0092 train_loss= 0.44762\n",
      "time= 0.01995\n",
      "Epoch: 0093 train_loss= 0.44714\n",
      "time= 0.01695\n",
      "Epoch: 0094 train_loss= 0.44667\n",
      "time= 0.03690\n",
      "Epoch: 0095 train_loss= 0.44621\n",
      "time= 0.03092\n",
      "Epoch: 0096 train_loss= 0.44577\n",
      "time= 0.02992\n",
      "Epoch: 0097 train_loss= 0.44534\n",
      "time= 0.02793\n",
      "Epoch: 0098 train_loss= 0.44492\n",
      "time= 0.02693\n",
      "Epoch: 0099 train_loss= 0.44451\n",
      "time= 0.02493\n",
      "Epoch: 0100 train_loss= 0.44411\n",
      "time= 0.02593\n",
      "ACC=0.664697, f1_macro=0.639627, precision_macro=0.647936, recall_macro=0.656312, f1_micro=0.664697, precision_micro=0.664697, recall_micro=0.664697, NMI=0.495425, ADJ_RAND_SCORE=0.430237\n",
      "Seed 3\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76678\n",
      "time= 0.01995\n",
      "Epoch: 0002 train_loss= 0.75967\n",
      "time= 0.01697\n",
      "Epoch: 0003 train_loss= 0.75124\n",
      "time= 0.01994\n",
      "Epoch: 0004 train_loss= 0.74307\n",
      "time= 0.02194\n",
      "Epoch: 0005 train_loss= 0.73777\n",
      "time= 0.02094\n",
      "Epoch: 0006 train_loss= 0.73785\n",
      "time= 0.02294\n",
      "Epoch: 0007 train_loss= 0.74054\n",
      "time= 0.02094\n",
      "Epoch: 0008 train_loss= 0.74030\n",
      "time= 0.02194\n",
      "Epoch: 0009 train_loss= 0.73695\n",
      "time= 0.02095\n",
      "Epoch: 0010 train_loss= 0.73297\n",
      "time= 0.01596\n",
      "Epoch: 0011 train_loss= 0.72956\n",
      "time= 0.01596\n",
      "Epoch: 0012 train_loss= 0.72640\n",
      "time= 0.01843\n",
      "Epoch: 0013 train_loss= 0.72310\n",
      "time= 0.01796\n",
      "Epoch: 0014 train_loss= 0.72026\n",
      "time= 0.01696\n",
      "Epoch: 0015 train_loss= 0.71675\n",
      "time= 0.01512\n",
      "Epoch: 0016 train_loss= 0.71238\n",
      "time= 0.01702\n",
      "Epoch: 0017 train_loss= 0.70724\n",
      "time= 0.01890\n",
      "Epoch: 0018 train_loss= 0.70141\n",
      "time= 0.01697\n",
      "Epoch: 0019 train_loss= 0.69506\n",
      "time= 0.01506\n",
      "Epoch: 0020 train_loss= 0.68835\n",
      "time= 0.02287\n",
      "Epoch: 0021 train_loss= 0.68139\n",
      "time= 0.01515\n",
      "Epoch: 0022 train_loss= 0.67422\n",
      "time= 0.01694\n",
      "Epoch: 0023 train_loss= 0.66683\n",
      "time= 0.01604\n",
      "Epoch: 0024 train_loss= 0.65915\n",
      "time= 0.01596\n",
      "Epoch: 0025 train_loss= 0.65119\n",
      "time= 0.01787\n",
      "Epoch: 0026 train_loss= 0.64303\n",
      "time= 0.01815\n",
      "Epoch: 0027 train_loss= 0.63481\n",
      "time= 0.01487\n",
      "Epoch: 0028 train_loss= 0.62668\n",
      "time= 0.01715\n",
      "Epoch: 0029 train_loss= 0.61880\n",
      "time= 0.01596\n",
      "Epoch: 0030 train_loss= 0.61130\n",
      "time= 0.01687\n",
      "Epoch: 0031 train_loss= 0.60422\n",
      "time= 0.01795\n",
      "Epoch: 0032 train_loss= 0.59757\n",
      "time= 0.01708\n",
      "Epoch: 0033 train_loss= 0.59131\n",
      "time= 0.01613\n",
      "Epoch: 0034 train_loss= 0.58537\n",
      "time= 0.01596\n",
      "Epoch: 0035 train_loss= 0.57965\n",
      "time= 0.01806\n",
      "Epoch: 0036 train_loss= 0.57408\n",
      "time= 0.01596\n",
      "Epoch: 0037 train_loss= 0.56862\n",
      "time= 0.01587\n",
      "Epoch: 0038 train_loss= 0.56327\n",
      "time= 0.01715\n",
      "Epoch: 0039 train_loss= 0.55801\n",
      "time= 0.01795\n",
      "Epoch: 0040 train_loss= 0.55287\n",
      "time= 0.01795\n",
      "Epoch: 0041 train_loss= 0.54786\n",
      "time= 0.01696\n",
      "Epoch: 0042 train_loss= 0.54302\n",
      "time= 0.01916\n",
      "Epoch: 0043 train_loss= 0.53837\n",
      "time= 0.01596\n",
      "Epoch: 0044 train_loss= 0.53398\n",
      "time= 0.01612\n",
      "Epoch: 0045 train_loss= 0.52991\n",
      "time= 0.01690\n",
      "Epoch: 0046 train_loss= 0.52620\n",
      "time= 0.01587\n",
      "Epoch: 0047 train_loss= 0.52287\n",
      "time= 0.01515\n",
      "Epoch: 0048 train_loss= 0.51994\n",
      "time= 0.01696\n",
      "Epoch: 0049 train_loss= 0.51739\n",
      "time= 0.01606\n",
      "Epoch: 0050 train_loss= 0.51518\n",
      "time= 0.01795\n",
      "Epoch: 0051 train_loss= 0.51327\n",
      "time= 0.02685\n",
      "Epoch: 0052 train_loss= 0.51161\n",
      "time= 0.01895\n",
      "Epoch: 0053 train_loss= 0.51016\n",
      "time= 0.02494\n",
      "Epoch: 0054 train_loss= 0.50885\n",
      "time= 0.01895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0055 train_loss= 0.50762\n",
      "time= 0.01795\n",
      "Epoch: 0056 train_loss= 0.50644\n",
      "time= 0.02094\n",
      "Epoch: 0057 train_loss= 0.50527\n",
      "time= 0.02493\n",
      "Epoch: 0058 train_loss= 0.50408\n",
      "time= 0.02892\n",
      "Epoch: 0059 train_loss= 0.50285\n",
      "time= 0.02593\n",
      "Epoch: 0060 train_loss= 0.50158\n",
      "time= 0.02693\n",
      "Epoch: 0061 train_loss= 0.50026\n",
      "time= 0.02892\n",
      "Epoch: 0062 train_loss= 0.49890\n",
      "time= 0.02693\n",
      "Epoch: 0063 train_loss= 0.49750\n",
      "time= 0.02693\n",
      "Epoch: 0064 train_loss= 0.49610\n",
      "time= 0.03092\n",
      "Epoch: 0065 train_loss= 0.49468\n",
      "time= 0.02593\n",
      "Epoch: 0066 train_loss= 0.49328\n",
      "time= 0.02593\n",
      "Epoch: 0067 train_loss= 0.49190\n",
      "time= 0.01795\n",
      "Epoch: 0068 train_loss= 0.49056\n",
      "time= 0.01696\n",
      "Epoch: 0069 train_loss= 0.48927\n",
      "time= 0.02094\n",
      "Epoch: 0070 train_loss= 0.48803\n",
      "time= 0.03291\n",
      "Epoch: 0071 train_loss= 0.48685\n",
      "time= 0.02892\n",
      "Epoch: 0072 train_loss= 0.48573\n",
      "time= 0.03191\n",
      "Epoch: 0073 train_loss= 0.48467\n",
      "time= 0.02792\n",
      "Epoch: 0074 train_loss= 0.48366\n",
      "time= 0.02992\n",
      "Epoch: 0075 train_loss= 0.48269\n",
      "time= 0.02394\n",
      "Epoch: 0076 train_loss= 0.48175\n",
      "time= 0.02792\n",
      "Epoch: 0077 train_loss= 0.48085\n",
      "time= 0.02593\n",
      "Epoch: 0078 train_loss= 0.47996\n",
      "time= 0.02593\n",
      "Epoch: 0079 train_loss= 0.47910\n",
      "time= 0.01695\n",
      "Epoch: 0080 train_loss= 0.47826\n",
      "time= 0.02294\n",
      "Epoch: 0081 train_loss= 0.47743\n",
      "time= 0.02693\n",
      "Epoch: 0082 train_loss= 0.47662\n",
      "time= 0.02792\n",
      "Epoch: 0083 train_loss= 0.47582\n",
      "time= 0.02493\n",
      "Epoch: 0084 train_loss= 0.47504\n",
      "time= 0.02593\n",
      "Epoch: 0085 train_loss= 0.47428\n",
      "time= 0.02892\n",
      "Epoch: 0086 train_loss= 0.47354\n",
      "time= 0.02992\n",
      "Epoch: 0087 train_loss= 0.47282\n",
      "time= 0.02593\n",
      "Epoch: 0088 train_loss= 0.47211\n",
      "time= 0.02792\n",
      "Epoch: 0089 train_loss= 0.47142\n",
      "time= 0.02693\n",
      "Epoch: 0090 train_loss= 0.47075\n",
      "time= 0.02992\n",
      "Epoch: 0091 train_loss= 0.47010\n",
      "time= 0.01895\n",
      "Epoch: 0092 train_loss= 0.46946\n",
      "time= 0.01795\n",
      "Epoch: 0093 train_loss= 0.46884\n",
      "time= 0.03092\n",
      "Epoch: 0094 train_loss= 0.46823\n",
      "time= 0.02793\n",
      "Epoch: 0095 train_loss= 0.46764\n",
      "time= 0.02892\n",
      "Epoch: 0096 train_loss= 0.46706\n",
      "time= 0.02693\n",
      "Epoch: 0097 train_loss= 0.46649\n",
      "time= 0.03191\n",
      "Epoch: 0098 train_loss= 0.46594\n",
      "time= 0.02892\n",
      "Epoch: 0099 train_loss= 0.46541\n",
      "time= 0.02892\n",
      "Epoch: 0100 train_loss= 0.46489\n",
      "time= 0.02394\n",
      "ACC=0.652511, f1_macro=0.633217, precision_macro=0.638304, recall_macro=0.672365, f1_micro=0.652511, precision_micro=0.652511, recall_micro=0.652511, NMI=0.468910, ADJ_RAND_SCORE=0.416346\n",
      "Seed 4\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76226\n",
      "time= 0.03092\n",
      "Epoch: 0002 train_loss= 0.75422\n",
      "time= 0.02992\n",
      "Epoch: 0003 train_loss= 0.74424\n",
      "time= 0.02892\n",
      "Epoch: 0004 train_loss= 0.73340\n",
      "time= 0.02992\n",
      "Epoch: 0005 train_loss= 0.72340\n",
      "time= 0.02703\n",
      "Epoch: 0006 train_loss= 0.71699\n",
      "time= 0.02793\n",
      "Epoch: 0007 train_loss= 0.71556\n",
      "time= 0.02694\n",
      "Epoch: 0008 train_loss= 0.71439\n",
      "time= 0.01900\n",
      "Epoch: 0009 train_loss= 0.70959\n",
      "time= 0.01795\n",
      "Epoch: 0010 train_loss= 0.70261\n",
      "time= 0.02014\n",
      "Epoch: 0011 train_loss= 0.69542\n",
      "time= 0.02793\n",
      "Epoch: 0012 train_loss= 0.69067\n",
      "time= 0.02992\n",
      "Epoch: 0013 train_loss= 0.68707\n",
      "time= 0.02595\n",
      "Epoch: 0014 train_loss= 0.68319\n",
      "time= 0.02530\n",
      "Epoch: 0015 train_loss= 0.67987\n",
      "time= 0.02828\n",
      "Epoch: 0016 train_loss= 0.67593\n",
      "time= 0.03491\n",
      "Epoch: 0017 train_loss= 0.67122\n",
      "time= 0.03092\n",
      "Epoch: 0018 train_loss= 0.66579\n",
      "time= 0.02793\n",
      "Epoch: 0019 train_loss= 0.65977\n",
      "time= 0.02792\n",
      "Epoch: 0020 train_loss= 0.65334\n",
      "time= 0.01795\n",
      "Epoch: 0021 train_loss= 0.64666\n",
      "time= 0.02245\n",
      "Epoch: 0022 train_loss= 0.63984\n",
      "time= 0.01895\n",
      "Epoch: 0023 train_loss= 0.63289\n",
      "time= 0.02793\n",
      "Epoch: 0024 train_loss= 0.62577\n",
      "time= 0.02793\n",
      "Epoch: 0025 train_loss= 0.61842\n",
      "time= 0.02992\n",
      "Epoch: 0026 train_loss= 0.61086\n",
      "time= 0.02892\n",
      "Epoch: 0027 train_loss= 0.60312\n",
      "time= 0.02793\n",
      "Epoch: 0028 train_loss= 0.59532\n",
      "time= 0.02594\n",
      "Epoch: 0029 train_loss= 0.58755\n",
      "time= 0.02692\n",
      "Epoch: 0030 train_loss= 0.57992\n",
      "time= 0.02892\n",
      "Epoch: 0031 train_loss= 0.57249\n",
      "time= 0.03092\n",
      "Epoch: 0032 train_loss= 0.56530\n",
      "time= 0.02095\n",
      "Epoch: 0033 train_loss= 0.55838\n",
      "time= 0.01995\n",
      "Epoch: 0034 train_loss= 0.55173\n",
      "time= 0.01895\n",
      "Epoch: 0035 train_loss= 0.54534\n",
      "time= 0.02792\n",
      "Epoch: 0036 train_loss= 0.53919\n",
      "time= 0.02892\n",
      "Epoch: 0037 train_loss= 0.53326\n",
      "time= 0.03690\n",
      "Epoch: 0038 train_loss= 0.52754\n",
      "time= 0.02892\n",
      "Epoch: 0039 train_loss= 0.52204\n",
      "time= 0.02793\n",
      "Epoch: 0040 train_loss= 0.51676\n",
      "time= 0.02793\n",
      "Epoch: 0041 train_loss= 0.51168\n",
      "time= 0.02593\n",
      "Epoch: 0042 train_loss= 0.50680\n",
      "time= 0.03092\n",
      "Epoch: 0043 train_loss= 0.50213\n",
      "time= 0.02493\n",
      "Epoch: 0044 train_loss= 0.49767\n",
      "time= 0.01795\n",
      "Epoch: 0045 train_loss= 0.49346\n",
      "time= 0.01795\n",
      "Epoch: 0046 train_loss= 0.48954\n",
      "time= 0.02892\n",
      "Epoch: 0047 train_loss= 0.48590\n",
      "time= 0.02593\n",
      "Epoch: 0048 train_loss= 0.48258\n",
      "time= 0.02693\n",
      "Epoch: 0049 train_loss= 0.47957\n",
      "time= 0.02992\n",
      "Epoch: 0050 train_loss= 0.47686\n",
      "time= 0.02792\n",
      "Epoch: 0051 train_loss= 0.47444\n",
      "time= 0.02892\n",
      "Epoch: 0052 train_loss= 0.47230\n",
      "time= 0.02892\n",
      "Epoch: 0053 train_loss= 0.47039\n",
      "time= 0.02493\n",
      "Epoch: 0054 train_loss= 0.46868\n",
      "time= 0.02793\n",
      "Epoch: 0055 train_loss= 0.46710\n",
      "time= 0.02393\n",
      "Epoch: 0056 train_loss= 0.46562\n",
      "time= 0.01795\n",
      "Epoch: 0057 train_loss= 0.46420\n",
      "time= 0.02793\n",
      "Epoch: 0058 train_loss= 0.46280\n",
      "time= 0.02693\n",
      "Epoch: 0059 train_loss= 0.46140\n",
      "time= 0.02911\n",
      "Epoch: 0060 train_loss= 0.45998\n",
      "time= 0.02593\n",
      "Epoch: 0061 train_loss= 0.45854\n",
      "time= 0.02992\n",
      "Epoch: 0062 train_loss= 0.45708\n",
      "time= 0.02792\n",
      "Epoch: 0063 train_loss= 0.45561\n",
      "time= 0.02693\n",
      "Epoch: 0064 train_loss= 0.45414\n",
      "time= 0.02992\n",
      "Epoch: 0065 train_loss= 0.45271\n",
      "time= 0.02792\n",
      "Epoch: 0066 train_loss= 0.45131\n",
      "time= 0.02294\n",
      "Epoch: 0067 train_loss= 0.44997\n",
      "time= 0.01795\n",
      "Epoch: 0068 train_loss= 0.44870\n",
      "time= 0.01695\n",
      "Epoch: 0069 train_loss= 0.44752\n",
      "time= 0.02792\n",
      "Epoch: 0070 train_loss= 0.44643\n",
      "time= 0.02773\n",
      "Epoch: 0071 train_loss= 0.44541\n",
      "time= 0.02593\n",
      "Epoch: 0072 train_loss= 0.44448\n",
      "time= 0.02792\n",
      "Epoch: 0073 train_loss= 0.44361\n",
      "time= 0.01795\n",
      "Epoch: 0074 train_loss= 0.44279\n",
      "time= 0.03116\n",
      "Epoch: 0075 train_loss= 0.44202\n",
      "time= 0.02194\n",
      "Epoch: 0076 train_loss= 0.44128\n",
      "time= 0.02594\n",
      "Epoch: 0077 train_loss= 0.44056\n",
      "time= 0.02991\n",
      "Epoch: 0078 train_loss= 0.43986\n",
      "time= 0.03542\n",
      "Epoch: 0079 train_loss= 0.43918\n",
      "time= 0.01695\n",
      "Epoch: 0080 train_loss= 0.43850\n",
      "time= 0.01895\n",
      "Epoch: 0081 train_loss= 0.43783\n",
      "time= 0.01895\n",
      "Epoch: 0082 train_loss= 0.43717\n",
      "time= 0.02943\n",
      "Epoch: 0083 train_loss= 0.43652\n",
      "time= 0.02793\n",
      "Epoch: 0084 train_loss= 0.43588\n",
      "time= 0.02693\n",
      "Epoch: 0085 train_loss= 0.43525\n",
      "time= 0.02693\n",
      "Epoch: 0086 train_loss= 0.43462\n",
      "time= 0.02992\n",
      "Epoch: 0087 train_loss= 0.43401\n",
      "time= 0.02693\n",
      "Epoch: 0088 train_loss= 0.43341\n",
      "time= 0.02593\n",
      "Epoch: 0089 train_loss= 0.43282\n",
      "time= 0.02593\n",
      "Epoch: 0090 train_loss= 0.43223\n",
      "time= 0.03690\n",
      "Epoch: 0091 train_loss= 0.43165\n",
      "time= 0.01695\n",
      "Epoch: 0092 train_loss= 0.43107\n",
      "time= 0.01796\n",
      "Epoch: 0093 train_loss= 0.43050\n",
      "time= 0.01993\n",
      "Epoch: 0094 train_loss= 0.42995\n",
      "time= 0.02693\n",
      "Epoch: 0095 train_loss= 0.42940\n",
      "time= 0.02992\n",
      "Epoch: 0096 train_loss= 0.42886\n",
      "time= 0.02693\n",
      "Epoch: 0097 train_loss= 0.42834\n",
      "time= 0.02793\n",
      "Epoch: 0098 train_loss= 0.42783\n",
      "time= 0.02493\n",
      "Epoch: 0099 train_loss= 0.42733\n",
      "time= 0.03291\n",
      "Epoch: 0100 train_loss= 0.42684\n",
      "time= 0.02194\n",
      "ACC=0.682053, f1_macro=0.659229, precision_macro=0.670620, recall_macro=0.686340, f1_micro=0.682053, precision_micro=0.682053, recall_micro=0.682053, NMI=0.484729, ADJ_RAND_SCORE=0.454655\n",
      "Seed 5\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76925\n",
      "time= 0.03191\n",
      "Epoch: 0002 train_loss= 0.76387\n",
      "time= 0.02793\n",
      "Epoch: 0003 train_loss= 0.75637\n",
      "time= 0.03191\n",
      "Epoch: 0004 train_loss= 0.74730\n",
      "time= 0.02992\n",
      "Epoch: 0005 train_loss= 0.73715\n",
      "time= 0.03092\n",
      "Epoch: 0006 train_loss= 0.72700\n",
      "time= 0.02693\n",
      "Epoch: 0007 train_loss= 0.71869\n",
      "time= 0.02493\n",
      "Epoch: 0008 train_loss= 0.71426\n",
      "time= 0.02593\n",
      "Epoch: 0009 train_loss= 0.71346\n",
      "time= 0.02693\n",
      "Epoch: 0010 train_loss= 0.71191\n",
      "time= 0.01695\n",
      "Epoch: 0011 train_loss= 0.70740\n",
      "time= 0.01795\n",
      "Epoch: 0012 train_loss= 0.70187\n",
      "time= 0.01848\n",
      "Epoch: 0013 train_loss= 0.69510\n",
      "time= 0.02693\n",
      "Epoch: 0014 train_loss= 0.68971\n",
      "time= 0.02693\n",
      "Epoch: 0015 train_loss= 0.68516\n",
      "time= 0.02693\n",
      "Epoch: 0016 train_loss= 0.68109\n",
      "time= 0.02745\n",
      "Epoch: 0017 train_loss= 0.67704\n",
      "time= 0.03092\n",
      "Epoch: 0018 train_loss= 0.67264\n",
      "time= 0.03491\n",
      "Epoch: 0019 train_loss= 0.66770\n",
      "time= 0.02823\n",
      "Epoch: 0020 train_loss= 0.66211\n",
      "time= 0.02693\n",
      "Epoch: 0021 train_loss= 0.65591\n",
      "time= 0.02693\n",
      "Epoch: 0022 train_loss= 0.64917\n",
      "time= 0.01995\n",
      "Epoch: 0023 train_loss= 0.64200\n",
      "time= 0.01746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0024 train_loss= 0.63450\n",
      "time= 0.01995\n",
      "Epoch: 0025 train_loss= 0.62675\n",
      "time= 0.02693\n",
      "Epoch: 0026 train_loss= 0.61881\n",
      "time= 0.02693\n",
      "Epoch: 0027 train_loss= 0.61071\n",
      "time= 0.02843\n",
      "Epoch: 0028 train_loss= 0.60249\n",
      "time= 0.02793\n",
      "Epoch: 0029 train_loss= 0.59419\n",
      "time= 0.02792\n",
      "Epoch: 0030 train_loss= 0.58587\n",
      "time= 0.02693\n",
      "Epoch: 0031 train_loss= 0.57760\n",
      "time= 0.02693\n",
      "Epoch: 0032 train_loss= 0.56946\n",
      "time= 0.02593\n",
      "Epoch: 0033 train_loss= 0.56153\n",
      "time= 0.02793\n",
      "Epoch: 0034 train_loss= 0.55392\n",
      "time= 0.01795\n",
      "Epoch: 0035 train_loss= 0.54670\n",
      "time= 0.01596\n",
      "Epoch: 0036 train_loss= 0.53997\n",
      "time= 0.01795\n",
      "Epoch: 0037 train_loss= 0.53377\n",
      "time= 0.01596\n",
      "Epoch: 0038 train_loss= 0.52813\n",
      "time= 0.01596\n",
      "Epoch: 0039 train_loss= 0.52307\n",
      "time= 0.01795\n",
      "Epoch: 0040 train_loss= 0.51857\n",
      "time= 0.01696\n",
      "Epoch: 0041 train_loss= 0.51462\n",
      "time= 0.01596\n",
      "Epoch: 0042 train_loss= 0.51113\n",
      "time= 0.01995\n",
      "Epoch: 0043 train_loss= 0.50798\n",
      "time= 0.01596\n",
      "Epoch: 0044 train_loss= 0.50508\n",
      "time= 0.01695\n",
      "Epoch: 0045 train_loss= 0.50235\n",
      "time= 0.01696\n",
      "Epoch: 0046 train_loss= 0.49975\n",
      "time= 0.01596\n",
      "Epoch: 0047 train_loss= 0.49723\n",
      "time= 0.01596\n",
      "Epoch: 0048 train_loss= 0.49477\n",
      "time= 0.01695\n",
      "Epoch: 0049 train_loss= 0.49230\n",
      "time= 0.01596\n",
      "Epoch: 0050 train_loss= 0.48983\n",
      "time= 0.01695\n",
      "Epoch: 0051 train_loss= 0.48735\n",
      "time= 0.01696\n",
      "Epoch: 0052 train_loss= 0.48489\n",
      "time= 0.02094\n",
      "Epoch: 0053 train_loss= 0.48246\n",
      "time= 0.01995\n",
      "Epoch: 0054 train_loss= 0.48006\n",
      "time= 0.01797\n",
      "Epoch: 0055 train_loss= 0.47769\n",
      "time= 0.01494\n",
      "Epoch: 0056 train_loss= 0.47535\n",
      "time= 0.01795\n",
      "Epoch: 0057 train_loss= 0.47305\n",
      "time= 0.01695\n",
      "Epoch: 0058 train_loss= 0.47079\n",
      "time= 0.01995\n",
      "Epoch: 0059 train_loss= 0.46860\n",
      "time= 0.01795\n",
      "Epoch: 0060 train_loss= 0.46648\n",
      "time= 0.01695\n",
      "Epoch: 0061 train_loss= 0.46443\n",
      "time= 0.01895\n",
      "Epoch: 0062 train_loss= 0.46247\n",
      "time= 0.01695\n",
      "Epoch: 0063 train_loss= 0.46061\n",
      "time= 0.01695\n",
      "Epoch: 0064 train_loss= 0.45887\n",
      "time= 0.01597\n",
      "Epoch: 0065 train_loss= 0.45726\n",
      "time= 0.01496\n",
      "Epoch: 0066 train_loss= 0.45578\n",
      "time= 0.01696\n",
      "Epoch: 0067 train_loss= 0.45443\n",
      "time= 0.01596\n",
      "Epoch: 0068 train_loss= 0.45320\n",
      "time= 0.01996\n",
      "Epoch: 0069 train_loss= 0.45209\n",
      "time= 0.01694\n",
      "Epoch: 0070 train_loss= 0.45108\n",
      "time= 0.01895\n",
      "Epoch: 0071 train_loss= 0.45017\n",
      "time= 0.01696\n",
      "Epoch: 0072 train_loss= 0.44933\n",
      "time= 0.01596\n",
      "Epoch: 0073 train_loss= 0.44854\n",
      "time= 0.01795\n",
      "Epoch: 0074 train_loss= 0.44779\n",
      "time= 0.01695\n",
      "Epoch: 0075 train_loss= 0.44706\n",
      "time= 0.01596\n",
      "Epoch: 0076 train_loss= 0.44635\n",
      "time= 0.01850\n",
      "Epoch: 0077 train_loss= 0.44564\n",
      "time= 0.01700\n",
      "Epoch: 0078 train_loss= 0.44493\n",
      "time= 0.01529\n",
      "Epoch: 0079 train_loss= 0.44422\n",
      "time= 0.01560\n",
      "Epoch: 0080 train_loss= 0.44350\n",
      "time= 0.01795\n",
      "Epoch: 0081 train_loss= 0.44278\n",
      "time= 0.01795\n",
      "Epoch: 0082 train_loss= 0.44206\n",
      "time= 0.01695\n",
      "Epoch: 0083 train_loss= 0.44133\n",
      "time= 0.01795\n",
      "Epoch: 0084 train_loss= 0.44060\n",
      "time= 0.02095\n",
      "Epoch: 0085 train_loss= 0.43988\n",
      "time= 0.01695\n",
      "Epoch: 0086 train_loss= 0.43917\n",
      "time= 0.01795\n",
      "Epoch: 0087 train_loss= 0.43847\n",
      "time= 0.01795\n",
      "Epoch: 0088 train_loss= 0.43778\n",
      "time= 0.01876\n",
      "Epoch: 0089 train_loss= 0.43711\n",
      "time= 0.01695\n",
      "Epoch: 0090 train_loss= 0.43645\n",
      "time= 0.01795\n",
      "Epoch: 0091 train_loss= 0.43581\n",
      "time= 0.01895\n",
      "Epoch: 0092 train_loss= 0.43519\n",
      "time= 0.01596\n",
      "Epoch: 0093 train_loss= 0.43459\n",
      "time= 0.01695\n",
      "Epoch: 0094 train_loss= 0.43401\n",
      "time= 0.01496\n",
      "Epoch: 0095 train_loss= 0.43345\n",
      "time= 0.01895\n",
      "Epoch: 0096 train_loss= 0.43291\n",
      "time= 0.01596\n",
      "Epoch: 0097 train_loss= 0.43240\n",
      "time= 0.01695\n",
      "Epoch: 0098 train_loss= 0.43190\n",
      "time= 0.01596\n",
      "Epoch: 0099 train_loss= 0.43143\n",
      "time= 0.01596\n",
      "Epoch: 0100 train_loss= 0.43097\n",
      "time= 0.02394\n",
      "ACC=0.638848, f1_macro=0.617380, precision_macro=0.626964, recall_macro=0.643421, f1_micro=0.638848, precision_micro=0.638848, recall_micro=0.638848, NMI=0.469058, ADJ_RAND_SCORE=0.422237\n",
      "Seed 6\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76438\n",
      "time= 0.02992\n",
      "Epoch: 0002 train_loss= 0.75724\n",
      "time= 0.03092\n",
      "Epoch: 0003 train_loss= 0.74881\n",
      "time= 0.02892\n",
      "Epoch: 0004 train_loss= 0.73930\n",
      "time= 0.03192\n",
      "Epoch: 0005 train_loss= 0.72973\n",
      "time= 0.02792\n",
      "Epoch: 0006 train_loss= 0.72196\n",
      "time= 0.02094\n",
      "Epoch: 0007 train_loss= 0.71815\n",
      "time= 0.01995\n",
      "Epoch: 0008 train_loss= 0.71774\n",
      "time= 0.02992\n",
      "Epoch: 0009 train_loss= 0.71609\n",
      "time= 0.02892\n",
      "Epoch: 0010 train_loss= 0.71116\n",
      "time= 0.02792\n",
      "Epoch: 0011 train_loss= 0.70466\n",
      "time= 0.02793\n",
      "Epoch: 0012 train_loss= 0.69883\n",
      "time= 0.03590\n",
      "Epoch: 0013 train_loss= 0.69376\n",
      "time= 0.02493\n",
      "Epoch: 0014 train_loss= 0.68858\n",
      "time= 0.02892\n",
      "Epoch: 0015 train_loss= 0.68377\n",
      "time= 0.02792\n",
      "Epoch: 0016 train_loss= 0.67867\n",
      "time= 0.02593\n",
      "Epoch: 0017 train_loss= 0.67303\n",
      "time= 0.02094\n",
      "Epoch: 0018 train_loss= 0.66666\n",
      "time= 0.01895\n",
      "Epoch: 0019 train_loss= 0.65955\n",
      "time= 0.02792\n",
      "Epoch: 0020 train_loss= 0.65180\n",
      "time= 0.02992\n",
      "Epoch: 0021 train_loss= 0.64353\n",
      "time= 0.02793\n",
      "Epoch: 0022 train_loss= 0.63490\n",
      "time= 0.02793\n",
      "Epoch: 0023 train_loss= 0.62606\n",
      "time= 0.02692\n",
      "Epoch: 0024 train_loss= 0.61712\n",
      "time= 0.02992\n",
      "Epoch: 0025 train_loss= 0.60814\n",
      "time= 0.02693\n",
      "Epoch: 0026 train_loss= 0.59910\n",
      "time= 0.02793\n",
      "Epoch: 0027 train_loss= 0.58997\n",
      "time= 0.02593\n",
      "Epoch: 0028 train_loss= 0.58082\n",
      "time= 0.02693\n",
      "Epoch: 0029 train_loss= 0.57174\n",
      "time= 0.01695\n",
      "Epoch: 0030 train_loss= 0.56287\n",
      "time= 0.01791\n",
      "Epoch: 0031 train_loss= 0.55438\n",
      "time= 0.02893\n",
      "Epoch: 0032 train_loss= 0.54640\n",
      "time= 0.02892\n",
      "Epoch: 0033 train_loss= 0.53898\n",
      "time= 0.02792\n",
      "Epoch: 0034 train_loss= 0.53214\n",
      "time= 0.03690\n",
      "Epoch: 0035 train_loss= 0.52586\n",
      "time= 0.01895\n",
      "Epoch: 0036 train_loss= 0.52015\n",
      "time= 0.02394\n",
      "Epoch: 0037 train_loss= 0.51503\n",
      "time= 0.03544\n",
      "Epoch: 0038 train_loss= 0.51053\n",
      "time= 0.01795\n",
      "Epoch: 0039 train_loss= 0.50665\n",
      "time= 0.02593\n",
      "Epoch: 0040 train_loss= 0.50334\n",
      "time= 0.02693\n",
      "Epoch: 0041 train_loss= 0.50051\n",
      "time= 0.01795\n",
      "Epoch: 0042 train_loss= 0.49808\n",
      "time= 0.02126\n",
      "Epoch: 0043 train_loss= 0.49597\n",
      "time= 0.02793\n",
      "Epoch: 0044 train_loss= 0.49417\n",
      "time= 0.03092\n",
      "Epoch: 0045 train_loss= 0.49263\n",
      "time= 0.02843\n",
      "Epoch: 0046 train_loss= 0.49131\n",
      "time= 0.02693\n",
      "Epoch: 0047 train_loss= 0.49013\n",
      "time= 0.03790\n",
      "Epoch: 0048 train_loss= 0.48902\n",
      "time= 0.02593\n",
      "Epoch: 0049 train_loss= 0.48793\n",
      "time= 0.02694\n",
      "Epoch: 0050 train_loss= 0.48683\n",
      "time= 0.02691\n",
      "Epoch: 0051 train_loss= 0.48571\n",
      "time= 0.02892\n",
      "Epoch: 0052 train_loss= 0.48456\n",
      "time= 0.02194\n",
      "Epoch: 0053 train_loss= 0.48335\n",
      "time= 0.01696\n",
      "Epoch: 0054 train_loss= 0.48207\n",
      "time= 0.01895\n",
      "Epoch: 0055 train_loss= 0.48074\n",
      "time= 0.02992\n",
      "Epoch: 0056 train_loss= 0.47938\n",
      "time= 0.03591\n",
      "Epoch: 0057 train_loss= 0.47802\n",
      "time= 0.02792\n",
      "Epoch: 0058 train_loss= 0.47666\n",
      "time= 0.02892\n",
      "Epoch: 0059 train_loss= 0.47532\n",
      "time= 0.02593\n",
      "Epoch: 0060 train_loss= 0.47401\n",
      "time= 0.02693\n",
      "Epoch: 0061 train_loss= 0.47273\n",
      "time= 0.02792\n",
      "Epoch: 0062 train_loss= 0.47150\n",
      "time= 0.02992\n",
      "Epoch: 0063 train_loss= 0.47032\n",
      "time= 0.02693\n",
      "Epoch: 0064 train_loss= 0.46919\n",
      "time= 0.01596\n",
      "Epoch: 0065 train_loss= 0.46810\n",
      "time= 0.02095\n",
      "Epoch: 0066 train_loss= 0.46705\n",
      "time= 0.01994\n",
      "Epoch: 0067 train_loss= 0.46604\n",
      "time= 0.02693\n",
      "Epoch: 0068 train_loss= 0.46506\n",
      "time= 0.02693\n",
      "Epoch: 0069 train_loss= 0.46411\n",
      "time= 0.02992\n",
      "Epoch: 0070 train_loss= 0.46318\n",
      "time= 0.02593\n",
      "Epoch: 0071 train_loss= 0.46227\n",
      "time= 0.02793\n",
      "Epoch: 0072 train_loss= 0.46139\n",
      "time= 0.02693\n",
      "Epoch: 0073 train_loss= 0.46053\n",
      "time= 0.02593\n",
      "Epoch: 0074 train_loss= 0.45969\n",
      "time= 0.03092\n",
      "Epoch: 0075 train_loss= 0.45888\n",
      "time= 0.02493\n",
      "Epoch: 0076 train_loss= 0.45808\n",
      "time= 0.02593\n",
      "Epoch: 0077 train_loss= 0.45731\n",
      "time= 0.01695\n",
      "Epoch: 0078 train_loss= 0.45657\n",
      "time= 0.01596\n",
      "Epoch: 0079 train_loss= 0.45585\n",
      "time= 0.03092\n",
      "Epoch: 0080 train_loss= 0.45516\n",
      "time= 0.02743\n",
      "Epoch: 0081 train_loss= 0.45449\n",
      "time= 0.02892\n",
      "Epoch: 0082 train_loss= 0.45386\n",
      "time= 0.02593\n",
      "Epoch: 0083 train_loss= 0.45324\n",
      "time= 0.02693\n",
      "Epoch: 0084 train_loss= 0.45265\n",
      "time= 0.02845\n",
      "Epoch: 0085 train_loss= 0.45209\n",
      "time= 0.02892\n",
      "Epoch: 0086 train_loss= 0.45154\n",
      "time= 0.02793\n",
      "Epoch: 0087 train_loss= 0.45102\n",
      "time= 0.03691\n",
      "Epoch: 0088 train_loss= 0.45051\n",
      "time= 0.01797\n",
      "Epoch: 0089 train_loss= 0.45002\n",
      "time= 0.01594\n",
      "Epoch: 0090 train_loss= 0.44954\n",
      "time= 0.01895\n",
      "Epoch: 0091 train_loss= 0.44907\n",
      "time= 0.02992\n",
      "Epoch: 0092 train_loss= 0.44861\n",
      "time= 0.02784\n",
      "Epoch: 0093 train_loss= 0.44816\n",
      "time= 0.02792\n",
      "Epoch: 0094 train_loss= 0.44773\n",
      "time= 0.02793\n",
      "Epoch: 0095 train_loss= 0.44730\n",
      "time= 0.02992\n",
      "Epoch: 0096 train_loss= 0.44688\n",
      "time= 0.02693\n",
      "Epoch: 0097 train_loss= 0.44648\n",
      "time= 0.02992\n",
      "Epoch: 0098 train_loss= 0.44608\n",
      "time= 0.02893\n",
      "Epoch: 0099 train_loss= 0.44569\n",
      "time= 0.02249\n",
      "Epoch: 0100 train_loss= 0.44531\n",
      "time= 0.02693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC=0.721196, f1_macro=0.702950, precision_macro=0.693373, recall_macro=0.734620, f1_micro=0.721196, precision_micro=0.721196, recall_micro=0.721196, NMI=0.536972, ADJ_RAND_SCORE=0.495869\n",
      "Seed 7\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76767\n",
      "time= 0.04089\n",
      "Epoch: 0002 train_loss= 0.76136\n",
      "time= 0.03092\n",
      "Epoch: 0003 train_loss= 0.75336\n",
      "time= 0.02892\n",
      "Epoch: 0004 train_loss= 0.74451\n",
      "time= 0.02881\n",
      "Epoch: 0005 train_loss= 0.73575\n",
      "time= 0.02992\n",
      "Epoch: 0006 train_loss= 0.72891\n",
      "time= 0.02594\n",
      "Epoch: 0007 train_loss= 0.72577\n",
      "time= 0.01796\n",
      "Epoch: 0008 train_loss= 0.72592\n",
      "time= 0.01695\n",
      "Epoch: 0009 train_loss= 0.72545\n",
      "time= 0.02693\n",
      "Epoch: 0010 train_loss= 0.72222\n",
      "time= 0.02892\n",
      "Epoch: 0011 train_loss= 0.71702\n",
      "time= 0.02892\n",
      "Epoch: 0012 train_loss= 0.71191\n",
      "time= 0.02593\n",
      "Epoch: 0013 train_loss= 0.70632\n",
      "time= 0.02992\n",
      "Epoch: 0014 train_loss= 0.70173\n",
      "time= 0.02793\n",
      "Epoch: 0015 train_loss= 0.69825\n",
      "time= 0.02593\n",
      "Epoch: 0016 train_loss= 0.69453\n",
      "time= 0.02992\n",
      "Epoch: 0017 train_loss= 0.69042\n",
      "time= 0.02992\n",
      "Epoch: 0018 train_loss= 0.68574\n",
      "time= 0.02393\n",
      "Epoch: 0019 train_loss= 0.68046\n",
      "time= 0.01795\n",
      "Epoch: 0020 train_loss= 0.67460\n",
      "time= 0.01995\n",
      "Epoch: 0021 train_loss= 0.66824\n",
      "time= 0.02693\n",
      "Epoch: 0022 train_loss= 0.66146\n",
      "time= 0.02792\n",
      "Epoch: 0023 train_loss= 0.65435\n",
      "time= 0.02892\n",
      "Epoch: 0024 train_loss= 0.64695\n",
      "time= 0.02892\n",
      "Epoch: 0025 train_loss= 0.63928\n",
      "time= 0.02892\n",
      "Epoch: 0026 train_loss= 0.63136\n",
      "time= 0.02394\n",
      "Epoch: 0027 train_loss= 0.62326\n",
      "time= 0.02792\n",
      "Epoch: 0028 train_loss= 0.61503\n",
      "time= 0.02693\n",
      "Epoch: 0029 train_loss= 0.60677\n",
      "time= 0.02593\n",
      "Epoch: 0030 train_loss= 0.59853\n",
      "time= 0.02592\n",
      "Epoch: 0031 train_loss= 0.59040\n",
      "time= 0.01596\n",
      "Epoch: 0032 train_loss= 0.58243\n",
      "time= 0.01795\n",
      "Epoch: 0033 train_loss= 0.57468\n",
      "time= 0.02593\n",
      "Epoch: 0034 train_loss= 0.56722\n",
      "time= 0.02394\n",
      "Epoch: 0035 train_loss= 0.56010\n",
      "time= 0.02394\n",
      "Epoch: 0036 train_loss= 0.55337\n",
      "time= 0.02693\n",
      "Epoch: 0037 train_loss= 0.54702\n",
      "time= 0.02393\n",
      "Epoch: 0038 train_loss= 0.54104\n",
      "time= 0.03192\n",
      "Epoch: 0039 train_loss= 0.53543\n",
      "time= 0.02294\n",
      "Epoch: 0040 train_loss= 0.53017\n",
      "time= 0.02493\n",
      "Epoch: 0041 train_loss= 0.52523\n",
      "time= 0.03092\n",
      "Epoch: 0042 train_loss= 0.52060\n",
      "time= 0.02693\n",
      "Epoch: 0043 train_loss= 0.51624\n",
      "time= 0.02593\n",
      "Epoch: 0044 train_loss= 0.51213\n",
      "time= 0.01795\n",
      "Epoch: 0045 train_loss= 0.50824\n",
      "time= 0.01895\n",
      "Epoch: 0046 train_loss= 0.50458\n",
      "time= 0.02892\n",
      "Epoch: 0047 train_loss= 0.50113\n",
      "time= 0.03092\n",
      "Epoch: 0048 train_loss= 0.49791\n",
      "time= 0.02593\n",
      "Epoch: 0049 train_loss= 0.49493\n",
      "time= 0.03690\n",
      "Epoch: 0050 train_loss= 0.49218\n",
      "time= 0.02892\n",
      "Epoch: 0051 train_loss= 0.48965\n",
      "time= 0.02792\n",
      "Epoch: 0052 train_loss= 0.48732\n",
      "time= 0.02493\n",
      "Epoch: 0053 train_loss= 0.48519\n",
      "time= 0.02793\n",
      "Epoch: 0054 train_loss= 0.48324\n",
      "time= 0.02592\n",
      "Epoch: 0055 train_loss= 0.48145\n",
      "time= 0.02094\n",
      "Epoch: 0056 train_loss= 0.47982\n",
      "time= 0.01795\n",
      "Epoch: 0057 train_loss= 0.47831\n",
      "time= 0.01795\n",
      "Epoch: 0058 train_loss= 0.47693\n",
      "time= 0.02593\n",
      "Epoch: 0059 train_loss= 0.47564\n",
      "time= 0.03192\n",
      "Epoch: 0060 train_loss= 0.47444\n",
      "time= 0.02792\n",
      "Epoch: 0061 train_loss= 0.47333\n",
      "time= 0.02693\n",
      "Epoch: 0062 train_loss= 0.47227\n",
      "time= 0.03001\n",
      "Epoch: 0063 train_loss= 0.47128\n",
      "time= 0.02593\n",
      "Epoch: 0064 train_loss= 0.47033\n",
      "time= 0.02693\n",
      "Epoch: 0065 train_loss= 0.46941\n",
      "time= 0.03491\n",
      "Epoch: 0066 train_loss= 0.46851\n",
      "time= 0.02593\n",
      "Epoch: 0067 train_loss= 0.46763\n",
      "time= 0.01895\n",
      "Epoch: 0068 train_loss= 0.46677\n",
      "time= 0.01795\n",
      "Epoch: 0069 train_loss= 0.46591\n",
      "time= 0.01895\n",
      "Epoch: 0070 train_loss= 0.46506\n",
      "time= 0.02793\n",
      "Epoch: 0071 train_loss= 0.46421\n",
      "time= 0.02493\n",
      "Epoch: 0072 train_loss= 0.46338\n",
      "time= 0.02693\n",
      "Epoch: 0073 train_loss= 0.46255\n",
      "time= 0.03092\n",
      "Epoch: 0074 train_loss= 0.46174\n",
      "time= 0.02892\n",
      "Epoch: 0075 train_loss= 0.46094\n",
      "time= 0.02992\n",
      "Epoch: 0076 train_loss= 0.46016\n",
      "time= 0.02793\n",
      "Epoch: 0077 train_loss= 0.45941\n",
      "time= 0.02656\n",
      "Epoch: 0078 train_loss= 0.45867\n",
      "time= 0.02394\n",
      "Epoch: 0079 train_loss= 0.45795\n",
      "time= 0.01596\n",
      "Epoch: 0080 train_loss= 0.45725\n",
      "time= 0.01596\n",
      "Epoch: 0081 train_loss= 0.45656\n",
      "time= 0.01795\n",
      "Epoch: 0082 train_loss= 0.45589\n",
      "time= 0.01696\n",
      "Epoch: 0083 train_loss= 0.45523\n",
      "time= 0.01695\n",
      "Epoch: 0084 train_loss= 0.45458\n",
      "time= 0.01596\n",
      "Epoch: 0085 train_loss= 0.45395\n",
      "time= 0.01696\n",
      "Epoch: 0086 train_loss= 0.45334\n",
      "time= 0.01596\n",
      "Epoch: 0087 train_loss= 0.45274\n",
      "time= 0.01596\n",
      "Epoch: 0088 train_loss= 0.45215\n",
      "time= 0.01895\n",
      "Epoch: 0089 train_loss= 0.45157\n",
      "time= 0.01895\n",
      "Epoch: 0090 train_loss= 0.45100\n",
      "time= 0.01696\n",
      "Epoch: 0091 train_loss= 0.45044\n",
      "time= 0.01695\n",
      "Epoch: 0092 train_loss= 0.44989\n",
      "time= 0.01895\n",
      "Epoch: 0093 train_loss= 0.44935\n",
      "time= 0.01695\n",
      "Epoch: 0094 train_loss= 0.44882\n",
      "time= 0.01995\n",
      "Epoch: 0095 train_loss= 0.44829\n",
      "time= 0.01895\n",
      "Epoch: 0096 train_loss= 0.44776\n",
      "time= 0.01596\n",
      "Epoch: 0097 train_loss= 0.44724\n",
      "time= 0.01895\n",
      "Epoch: 0098 train_loss= 0.44673\n",
      "time= 0.01796\n",
      "Epoch: 0099 train_loss= 0.44623\n",
      "time= 0.01595\n",
      "Epoch: 0100 train_loss= 0.44573\n",
      "time= 0.01696\n",
      "ACC=0.666544, f1_macro=0.646103, precision_macro=0.679441, recall_macro=0.678840, f1_micro=0.666544, precision_micro=0.666544, recall_micro=0.666544, NMI=0.483992, ADJ_RAND_SCORE=0.433184\n",
      "Seed 8\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76733\n",
      "time= 0.02194\n",
      "Epoch: 0002 train_loss= 0.76183\n",
      "time= 0.01596\n",
      "Epoch: 0003 train_loss= 0.75551\n",
      "time= 0.02493\n",
      "Epoch: 0004 train_loss= 0.74818\n",
      "time= 0.01895\n",
      "Epoch: 0005 train_loss= 0.74019\n",
      "time= 0.01995\n",
      "Epoch: 0006 train_loss= 0.73236\n",
      "time= 0.01795\n",
      "Epoch: 0007 train_loss= 0.72570\n",
      "time= 0.01696\n",
      "Epoch: 0008 train_loss= 0.72121\n",
      "time= 0.01895\n",
      "Epoch: 0009 train_loss= 0.71907\n",
      "time= 0.01895\n",
      "Epoch: 0010 train_loss= 0.71764\n",
      "time= 0.01596\n",
      "Epoch: 0011 train_loss= 0.71480\n",
      "time= 0.01695\n",
      "Epoch: 0012 train_loss= 0.71011\n",
      "time= 0.01596\n",
      "Epoch: 0013 train_loss= 0.70321\n",
      "time= 0.01696\n",
      "Epoch: 0014 train_loss= 0.69548\n",
      "time= 0.01496\n",
      "Epoch: 0015 train_loss= 0.68771\n",
      "time= 0.01795\n",
      "Epoch: 0016 train_loss= 0.67942\n",
      "time= 0.01795\n",
      "Epoch: 0017 train_loss= 0.67142\n",
      "time= 0.01596\n",
      "Epoch: 0018 train_loss= 0.66327\n",
      "time= 0.01647\n",
      "Epoch: 0019 train_loss= 0.65486\n",
      "time= 0.01695\n",
      "Epoch: 0020 train_loss= 0.64612\n",
      "time= 0.01695\n",
      "Epoch: 0021 train_loss= 0.63708\n",
      "time= 0.01995\n",
      "Epoch: 0022 train_loss= 0.62787\n",
      "time= 0.01696\n",
      "Epoch: 0023 train_loss= 0.61862\n",
      "time= 0.01695\n",
      "Epoch: 0024 train_loss= 0.60948\n",
      "time= 0.02498\n",
      "Epoch: 0025 train_loss= 0.60055\n",
      "time= 0.02002\n",
      "Epoch: 0026 train_loss= 0.59193\n",
      "time= 0.02397\n",
      "Epoch: 0027 train_loss= 0.58368\n",
      "time= 0.01696\n",
      "Epoch: 0028 train_loss= 0.57590\n",
      "time= 0.01904\n",
      "Epoch: 0029 train_loss= 0.56867\n",
      "time= 0.03092\n",
      "Epoch: 0030 train_loss= 0.56205\n",
      "time= 0.02847\n",
      "Epoch: 0031 train_loss= 0.55605\n",
      "time= 0.03392\n",
      "Epoch: 0032 train_loss= 0.55063\n",
      "time= 0.02992\n",
      "Epoch: 0033 train_loss= 0.54571\n",
      "time= 0.02893\n",
      "Epoch: 0034 train_loss= 0.54121\n",
      "time= 0.02513\n",
      "Epoch: 0035 train_loss= 0.53708\n",
      "time= 0.02693\n",
      "Epoch: 0036 train_loss= 0.53326\n",
      "time= 0.02892\n",
      "Epoch: 0037 train_loss= 0.52974\n",
      "time= 0.02594\n",
      "Epoch: 0038 train_loss= 0.52651\n",
      "time= 0.01994\n",
      "Epoch: 0039 train_loss= 0.52359\n",
      "time= 0.01895\n",
      "Epoch: 0040 train_loss= 0.52096\n",
      "time= 0.02593\n",
      "Epoch: 0041 train_loss= 0.51861\n",
      "time= 0.03291\n",
      "Epoch: 0042 train_loss= 0.51651\n",
      "time= 0.02793\n",
      "Epoch: 0043 train_loss= 0.51461\n",
      "time= 0.02493\n",
      "Epoch: 0044 train_loss= 0.51288\n",
      "time= 0.03191\n",
      "Epoch: 0045 train_loss= 0.51128\n",
      "time= 0.02892\n",
      "Epoch: 0046 train_loss= 0.50975\n",
      "time= 0.02593\n",
      "Epoch: 0047 train_loss= 0.50825\n",
      "time= 0.03191\n",
      "Epoch: 0048 train_loss= 0.50673\n",
      "time= 0.02592\n",
      "Epoch: 0049 train_loss= 0.50517\n",
      "time= 0.02843\n",
      "Epoch: 0050 train_loss= 0.50357\n",
      "time= 0.01895\n",
      "Epoch: 0051 train_loss= 0.50193\n",
      "time= 0.01795\n",
      "Epoch: 0052 train_loss= 0.50026\n",
      "time= 0.02792\n",
      "Epoch: 0053 train_loss= 0.49858\n",
      "time= 0.02693\n",
      "Epoch: 0054 train_loss= 0.49686\n",
      "time= 0.02793\n",
      "Epoch: 0055 train_loss= 0.49514\n",
      "time= 0.02693\n",
      "Epoch: 0056 train_loss= 0.49340\n",
      "time= 0.02793\n",
      "Epoch: 0057 train_loss= 0.49167\n",
      "time= 0.03690\n",
      "Epoch: 0058 train_loss= 0.48995\n",
      "time= 0.02593\n",
      "Epoch: 0059 train_loss= 0.48827\n",
      "time= 0.02693\n",
      "Epoch: 0060 train_loss= 0.48663\n",
      "time= 0.02793\n",
      "Epoch: 0061 train_loss= 0.48505\n",
      "time= 0.01795\n",
      "Epoch: 0062 train_loss= 0.48352\n",
      "time= 0.01995\n",
      "Epoch: 0063 train_loss= 0.48207\n",
      "time= 0.02094\n",
      "Epoch: 0064 train_loss= 0.48070\n",
      "time= 0.02693\n",
      "Epoch: 0065 train_loss= 0.47942\n",
      "time= 0.02693\n",
      "Epoch: 0066 train_loss= 0.47820\n",
      "time= 0.02892\n",
      "Epoch: 0067 train_loss= 0.47705\n",
      "time= 0.02892\n",
      "Epoch: 0068 train_loss= 0.47596\n",
      "time= 0.02892\n",
      "Epoch: 0069 train_loss= 0.47491\n",
      "time= 0.02593\n",
      "Epoch: 0070 train_loss= 0.47389\n",
      "time= 0.02593\n",
      "Epoch: 0071 train_loss= 0.47289\n",
      "time= 0.03192\n",
      "Epoch: 0072 train_loss= 0.47191\n",
      "time= 0.02294\n",
      "Epoch: 0073 train_loss= 0.47094\n",
      "time= 0.02792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0074 train_loss= 0.46999\n",
      "time= 0.01596\n",
      "Epoch: 0075 train_loss= 0.46905\n",
      "time= 0.01895\n",
      "Epoch: 0076 train_loss= 0.46814\n",
      "time= 0.02992\n",
      "Epoch: 0077 train_loss= 0.46724\n",
      "time= 0.02992\n",
      "Epoch: 0078 train_loss= 0.46637\n",
      "time= 0.02693\n",
      "Epoch: 0079 train_loss= 0.46553\n",
      "time= 0.02793\n",
      "Epoch: 0080 train_loss= 0.46472\n",
      "time= 0.02793\n",
      "Epoch: 0081 train_loss= 0.46394\n",
      "time= 0.02593\n",
      "Epoch: 0082 train_loss= 0.46320\n",
      "time= 0.02892\n",
      "Epoch: 0083 train_loss= 0.46249\n",
      "time= 0.02593\n",
      "Epoch: 0084 train_loss= 0.46180\n",
      "time= 0.02793\n",
      "Epoch: 0085 train_loss= 0.46114\n",
      "time= 0.02891\n",
      "Epoch: 0086 train_loss= 0.46050\n",
      "time= 0.01995\n",
      "Epoch: 0087 train_loss= 0.45988\n",
      "time= 0.01795\n",
      "Epoch: 0088 train_loss= 0.45928\n",
      "time= 0.02943\n",
      "Epoch: 0089 train_loss= 0.45870\n",
      "time= 0.02593\n",
      "Epoch: 0090 train_loss= 0.45813\n",
      "time= 0.02892\n",
      "Epoch: 0091 train_loss= 0.45759\n",
      "time= 0.02892\n",
      "Epoch: 0092 train_loss= 0.45707\n",
      "time= 0.02693\n",
      "Epoch: 0093 train_loss= 0.45656\n",
      "time= 0.02593\n",
      "Epoch: 0094 train_loss= 0.45608\n",
      "time= 0.02693\n",
      "Epoch: 0095 train_loss= 0.45561\n",
      "time= 0.02896\n",
      "Epoch: 0096 train_loss= 0.45516\n",
      "time= 0.02892\n",
      "Epoch: 0097 train_loss= 0.45473\n",
      "time= 0.02493\n",
      "Epoch: 0098 train_loss= 0.45431\n",
      "time= 0.01695\n",
      "Epoch: 0099 train_loss= 0.45389\n",
      "time= 0.02194\n",
      "Epoch: 0100 train_loss= 0.45349\n",
      "time= 0.02593\n",
      "ACC=0.652880, f1_macro=0.630524, precision_macro=0.641520, recall_macro=0.660403, f1_micro=0.652880, precision_micro=0.652880, recall_micro=0.652880, NMI=0.473266, ADJ_RAND_SCORE=0.437120\n",
      "Seed 9\n",
      "Using cora dataset\n",
      "Epoch: 0001 train_loss= 0.76189\n",
      "time= 0.02493\n",
      "Epoch: 0002 train_loss= 0.75337\n",
      "time= 0.02393\n",
      "Epoch: 0003 train_loss= 0.74359\n",
      "time= 0.02194\n",
      "Epoch: 0004 train_loss= 0.73406\n",
      "time= 0.02194\n",
      "Epoch: 0005 train_loss= 0.72785\n",
      "time= 0.03092\n",
      "Epoch: 0006 train_loss= 0.72695\n",
      "time= 0.02992\n",
      "Epoch: 0007 train_loss= 0.72867\n",
      "time= 0.02992\n",
      "Epoch: 0008 train_loss= 0.72776\n",
      "time= 0.02793\n",
      "Epoch: 0009 train_loss= 0.72390\n",
      "time= 0.02892\n",
      "Epoch: 0010 train_loss= 0.71915\n",
      "time= 0.02892\n",
      "Epoch: 0011 train_loss= 0.71502\n",
      "time= 0.02593\n",
      "Epoch: 0012 train_loss= 0.71259\n",
      "time= 0.02694\n",
      "Epoch: 0013 train_loss= 0.71116\n",
      "time= 0.02891\n",
      "Epoch: 0014 train_loss= 0.71022\n",
      "time= 0.02493\n",
      "Epoch: 0015 train_loss= 0.70833\n",
      "time= 0.01696\n",
      "Epoch: 0016 train_loss= 0.70530\n",
      "time= 0.01994\n",
      "Epoch: 0017 train_loss= 0.70128\n",
      "time= 0.02095\n",
      "Epoch: 0018 train_loss= 0.69631\n",
      "time= 0.02794\n",
      "Epoch: 0019 train_loss= 0.69092\n",
      "time= 0.02693\n",
      "Epoch: 0020 train_loss= 0.68527\n",
      "time= 0.02792\n",
      "Epoch: 0021 train_loss= 0.67943\n",
      "time= 0.02892\n",
      "Epoch: 0022 train_loss= 0.67339\n",
      "time= 0.02593\n",
      "Epoch: 0023 train_loss= 0.66707\n",
      "time= 0.02593\n",
      "Epoch: 0024 train_loss= 0.66032\n",
      "time= 0.02693\n",
      "Epoch: 0025 train_loss= 0.65308\n",
      "time= 0.02693\n",
      "Epoch: 0026 train_loss= 0.64538\n",
      "time= 0.02892\n",
      "Epoch: 0027 train_loss= 0.63733\n",
      "time= 0.02294\n",
      "Epoch: 0028 train_loss= 0.62904\n",
      "time= 0.01795\n",
      "Epoch: 0029 train_loss= 0.62060\n",
      "time= 0.01995\n",
      "Epoch: 0030 train_loss= 0.61208\n",
      "time= 0.02593\n",
      "Epoch: 0031 train_loss= 0.60352\n",
      "time= 0.02992\n",
      "Epoch: 0032 train_loss= 0.59494\n",
      "time= 0.02793\n",
      "Epoch: 0033 train_loss= 0.58638\n",
      "time= 0.02844\n",
      "Epoch: 0034 train_loss= 0.57791\n",
      "time= 0.03091\n",
      "Epoch: 0035 train_loss= 0.56962\n",
      "time= 0.02593\n",
      "Epoch: 0036 train_loss= 0.56162\n",
      "time= 0.02793\n",
      "Epoch: 0037 train_loss= 0.55397\n",
      "time= 0.02793\n",
      "Epoch: 0038 train_loss= 0.54673\n",
      "time= 0.02793\n",
      "Epoch: 0039 train_loss= 0.53992\n",
      "time= 0.02593\n",
      "Epoch: 0040 train_loss= 0.53352\n",
      "time= 0.01795\n",
      "Epoch: 0041 train_loss= 0.52756\n",
      "time= 0.01962\n",
      "Epoch: 0042 train_loss= 0.52202\n",
      "time= 0.02892\n",
      "Epoch: 0043 train_loss= 0.51693\n",
      "time= 0.02793\n",
      "Epoch: 0044 train_loss= 0.51226\n",
      "time= 0.02992\n",
      "Epoch: 0045 train_loss= 0.50800\n",
      "time= 0.03890\n",
      "Epoch: 0046 train_loss= 0.50412\n",
      "time= 0.02693\n",
      "Epoch: 0047 train_loss= 0.50062\n",
      "time= 0.02493\n",
      "Epoch: 0048 train_loss= 0.49749\n",
      "time= 0.02626\n",
      "Epoch: 0049 train_loss= 0.49471\n",
      "time= 0.02792\n",
      "Epoch: 0050 train_loss= 0.49228\n",
      "time= 0.02992\n",
      "Epoch: 0051 train_loss= 0.49015\n",
      "time= 0.01795\n",
      "Epoch: 0052 train_loss= 0.48831\n",
      "time= 0.01846\n",
      "Epoch: 0053 train_loss= 0.48673\n",
      "time= 0.01995\n",
      "Epoch: 0054 train_loss= 0.48535\n",
      "time= 0.03690\n",
      "Epoch: 0055 train_loss= 0.48415\n",
      "time= 0.03092\n",
      "Epoch: 0056 train_loss= 0.48308\n",
      "time= 0.02792\n",
      "Epoch: 0057 train_loss= 0.48210\n",
      "time= 0.03690\n",
      "Epoch: 0058 train_loss= 0.48119\n",
      "time= 0.02693\n",
      "Epoch: 0059 train_loss= 0.48032\n",
      "time= 0.02593\n",
      "Epoch: 0060 train_loss= 0.47947\n",
      "time= 0.02693\n",
      "Epoch: 0061 train_loss= 0.47864\n",
      "time= 0.02593\n",
      "Epoch: 0062 train_loss= 0.47781\n",
      "time= 0.01996\n",
      "Epoch: 0063 train_loss= 0.47698\n",
      "time= 0.01595\n",
      "Epoch: 0064 train_loss= 0.47614\n",
      "time= 0.02593\n",
      "Epoch: 0065 train_loss= 0.47530\n",
      "time= 0.02793\n",
      "Epoch: 0066 train_loss= 0.47447\n",
      "time= 0.03092\n",
      "Epoch: 0067 train_loss= 0.47364\n",
      "time= 0.02894\n",
      "Epoch: 0068 train_loss= 0.47281\n",
      "time= 0.02692\n",
      "Epoch: 0069 train_loss= 0.47200\n",
      "time= 0.02793\n",
      "Epoch: 0070 train_loss= 0.47121\n",
      "time= 0.02593\n",
      "Epoch: 0071 train_loss= 0.47044\n",
      "time= 0.02892\n",
      "Epoch: 0072 train_loss= 0.46970\n",
      "time= 0.02693\n",
      "Epoch: 0073 train_loss= 0.46899\n",
      "time= 0.02795\n",
      "Epoch: 0074 train_loss= 0.46830\n",
      "time= 0.01892\n",
      "Epoch: 0075 train_loss= 0.46764\n",
      "time= 0.01596\n",
      "Epoch: 0076 train_loss= 0.46701\n",
      "time= 0.01795\n",
      "Epoch: 0077 train_loss= 0.46640\n",
      "time= 0.03989\n",
      "Epoch: 0078 train_loss= 0.46581\n",
      "time= 0.02693\n",
      "Epoch: 0079 train_loss= 0.46523\n",
      "time= 0.03090\n",
      "Epoch: 0080 train_loss= 0.46466\n",
      "time= 0.02892\n",
      "Epoch: 0081 train_loss= 0.46410\n",
      "time= 0.02793\n",
      "Epoch: 0082 train_loss= 0.46356\n",
      "time= 0.02693\n",
      "Epoch: 0083 train_loss= 0.46301\n",
      "time= 0.02394\n",
      "Epoch: 0084 train_loss= 0.46248\n",
      "time= 0.02793\n",
      "Epoch: 0085 train_loss= 0.46194\n",
      "time= 0.02892\n",
      "Epoch: 0086 train_loss= 0.46141\n",
      "time= 0.02095\n",
      "Epoch: 0087 train_loss= 0.46089\n",
      "time= 0.01695\n",
      "Epoch: 0088 train_loss= 0.46037\n",
      "time= 0.01795\n",
      "Epoch: 0089 train_loss= 0.45986\n",
      "time= 0.03092\n",
      "Epoch: 0090 train_loss= 0.45936\n",
      "time= 0.02743\n",
      "Epoch: 0091 train_loss= 0.45886\n",
      "time= 0.02793\n",
      "Epoch: 0092 train_loss= 0.45838\n",
      "time= 0.02792\n",
      "Epoch: 0093 train_loss= 0.45791\n",
      "time= 0.02992\n",
      "Epoch: 0094 train_loss= 0.45745\n",
      "time= 0.02594\n",
      "Epoch: 0095 train_loss= 0.45701\n",
      "time= 0.02493\n",
      "Epoch: 0096 train_loss= 0.45657\n",
      "time= 0.02893\n",
      "Epoch: 0097 train_loss= 0.45615\n",
      "time= 0.02694\n",
      "Epoch: 0098 train_loss= 0.45573\n",
      "time= 0.02691\n",
      "Epoch: 0099 train_loss= 0.45533\n",
      "time= 0.01995\n",
      "Epoch: 0100 train_loss= 0.45494\n",
      "time= 0.01795\n",
      "ACC=0.660266, f1_macro=0.639605, precision_macro=0.650197, recall_macro=0.673200, f1_micro=0.660266, precision_micro=0.660266, recall_micro=0.660266, NMI=0.493433, ADJ_RAND_SCORE=0.444586\n",
      "acc = 0.6601181683899556 , std =  0.02739233143408342\n",
      "nmi = 0.4897500152505949 , std =  0.01886364031656808\n",
      "f1_macro = 0.6366324764564399 , std =  0.03197977220411297\n",
      "precision_macro = 0.6472487799009788 , std =  0.029826303541492086\n",
      "adjscore = 0.43802012000815954 , std =  0.02239350474931951\n"
     ]
    }
   ],
   "source": [
    "once = False\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if once == True:\n",
    "        gae_for(args)\n",
    "    else:\n",
    "        clustering_scores = []\n",
    "        clustering_metrics_names = ['acc', 'nmi', 'f1_macro', 'precision_macro', 'adjscore']\n",
    "        \n",
    "        # using 10 different random seeds\n",
    "        for seed in range(10):\n",
    "            print('Seed',seed)\n",
    "            args.seed = seed\n",
    "            torch.manual_seed(args.seed)\n",
    "            clustering_score = gae_for(args)\n",
    "            clustering_scores.append(clustering_score)\n",
    "        # show the results by mean and std\n",
    "        clustering_scores = np.asarray(clustering_scores)\n",
    "        for i in range(len(clustering_scores[0])):\n",
    "            print(clustering_metrics_names[i],'=',np.mean(clustering_scores[:,i]),', std = ',np.std(clustering_scores[:,i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
